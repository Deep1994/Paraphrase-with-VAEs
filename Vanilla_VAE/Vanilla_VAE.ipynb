{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cad6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25dff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/clean_paraphrases.tsv'\n",
    "q1_data = []\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        q1_data.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5610d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "febc94a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astrology : i am a capricorn sun cap moon and cap rising ... what does that say about me ?',\n",
       " 'how can i be a good geologist ?',\n",
       " 'how do i read and find my youtube comments ?',\n",
       " 'what can make physics easy to learn ?',\n",
       " 'what was your first sexual experience like ?',\n",
       " 'what would a trump presidency mean for current international master ’ s students on an f1 visa ?',\n",
       " 'what does manipulation mean ?',\n",
       " 'why are so many quora users posting questions that are readily answered on google ?',\n",
       " 'why do rockets look white ?',\n",
       " 'how should i prepare for ca final law ?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29631bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/qqp.train.txt', 'w') as f:\n",
    "    for line in q1_data[:-4000]:\n",
    "        f.write(line + '\\n') \n",
    "        \n",
    "with open('data/qqp.valid.txt', 'w') as f:\n",
    "    for line in q1_data[-4000:]:\n",
    "        f.write(line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6294bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QQP(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, split, create_data, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split\n",
    "        self.max_sequence_length = kwargs.get('max_sequence_length', 20)\n",
    "        self.min_occ = kwargs.get('min_occ', 3)\n",
    "\n",
    "        self.raw_data_path = os.path.join(data_dir, 'qqp.'+ split +'.txt')\n",
    "        self.data_file = 'qqp.'+ split +'.json'\n",
    "        self.vocab_file = 'qqp.vocab.json'\n",
    "\n",
    "        if create_data:\n",
    "            print(\"Creating new %s qqp data.\"%split.upper())\n",
    "            self._create_data()\n",
    "\n",
    "        elif not os.path.exists(os.path.join(self.data_dir, self.data_file)):\n",
    "            print(\"%s preprocessed file not found at %s. Creating new.\"%(split.upper(), os.path.join(self.data_dir, self.data_file)))\n",
    "            self._create_data()\n",
    "\n",
    "        else:\n",
    "            self._load_data()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = str(idx)\n",
    "\n",
    "        return {\n",
    "            'input': np.asarray(self.data[idx]['input']),\n",
    "            'target': np.asarray(self.data[idx]['target']),\n",
    "            'length': self.data[idx]['length']\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.w2i)\n",
    "\n",
    "    @property\n",
    "    def pad_idx(self):\n",
    "        return self.w2i['<pad>']\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self):\n",
    "        return self.w2i['<sos>']\n",
    "\n",
    "    @property\n",
    "    def eos_idx(self):\n",
    "        return self.w2i['<eos>']\n",
    "\n",
    "    @property\n",
    "    def unk_idx(self):\n",
    "        return self.w2i['<unk>']\n",
    "\n",
    "    def get_w2i(self):\n",
    "        return self.w2i\n",
    "\n",
    "    def get_i2w(self):\n",
    "        return self.i2w\n",
    "\n",
    "\n",
    "    def _load_data(self, vocab=True):\n",
    "\n",
    "        with open(os.path.join(self.data_dir, self.data_file), 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        if vocab:\n",
    "            with open(os.path.join(self.data_dir, self.vocab_file), 'r') as file:\n",
    "                vocab = json.load(file)\n",
    "            self.w2i, self.i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    def _load_vocab(self):\n",
    "        with open(os.path.join(self.data_dir, self.vocab_file), 'r') as vocab_file:\n",
    "            vocab = json.load(vocab_file)\n",
    "\n",
    "        self.w2i, self.i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    def _create_data(self):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            self._create_vocab()\n",
    "        else:\n",
    "            self._load_vocab()\n",
    "\n",
    "        tokenizer = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "        data = defaultdict(dict)\n",
    "        with open(self.raw_data_path, 'r') as f:\n",
    "\n",
    "            for i, line in enumerate(f):\n",
    "\n",
    "                words = tokenizer.tokenize(line)\n",
    "\n",
    "                input = ['<sos>'] + words\n",
    "                input = input[:self.max_sequence_length]\n",
    "\n",
    "                target = words[:self.max_sequence_length-1]\n",
    "                target = target + ['<eos>']\n",
    "\n",
    "                assert len(input) == len(target), \"%d, %d\"%(len(input), len(target))\n",
    "                length = len(input)\n",
    "\n",
    "                input.extend(['<pad>'] * (self.max_sequence_length-length))\n",
    "                target.extend(['<pad>'] * (self.max_sequence_length-length))\n",
    "\n",
    "                input = [self.w2i.get(w, self.w2i['<unk>']) for w in input]\n",
    "                target = [self.w2i.get(w, self.w2i['<unk>']) for w in target]\n",
    "\n",
    "                id = len(data)\n",
    "                data[id]['input'] = input\n",
    "                data[id]['target'] = target\n",
    "                data[id]['length'] = length\n",
    "\n",
    "        with io.open(os.path.join(self.data_dir, self.data_file), 'wb') as data_file:\n",
    "            data = json.dumps(data, ensure_ascii=False)\n",
    "            data_file.write(data.encode('utf8', 'replace'))\n",
    "\n",
    "        self._load_data(vocab=False)\n",
    "\n",
    "    def _create_vocab(self):\n",
    "\n",
    "        assert self.split == 'train', \"Vocablurary can only be created for training file.\"\n",
    "\n",
    "        tokenizer = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "        wordcounts = collections.Counter()\n",
    "        w2i = dict()\n",
    "        i2w = dict()\n",
    "\n",
    "        special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "        for st in special_tokens:\n",
    "            i2w[len(w2i)] = st\n",
    "            w2i[st] = len(w2i)\n",
    "\n",
    "        with open(self.raw_data_path, 'r') as f:\n",
    "\n",
    "            for line in f:\n",
    "                for word in tokenizer.tokenize(line):\n",
    "                    wordcounts[word] += 1\n",
    "                \n",
    "            for w, c in dict(wordcounts.most_common()).items():\n",
    "                if c > self.min_occ and w not in special_tokens:\n",
    "                    i2w[len(w2i)] = w\n",
    "                    w2i[w] = len(w2i)\n",
    "\n",
    "        assert len(w2i) == len(i2w)\n",
    "\n",
    "        print(\"Vocablurary of %i keys created.\" %len(w2i))\n",
    "\n",
    "        vocab = dict(w2i=w2i, i2w=i2w)\n",
    "        with io.open(os.path.join(self.data_dir, self.vocab_file), 'wb') as vocab_file:\n",
    "            data = json.dumps(vocab, ensure_ascii=False)\n",
    "            vocab_file.write(data.encode('utf8', 'replace'))\n",
    "\n",
    "        self._load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "783e885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TRAIN qqp data.\n",
      "Vocablurary of 11042 keys created.\n"
     ]
    }
   ],
   "source": [
    "train_data = QQP(\n",
    "            data_dir='data',\n",
    "            split='train',\n",
    "            create_data=True,\n",
    "            max_sequence_length=20,\n",
    "            min_occ=3\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9551c648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78645a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = dict()\n",
    "i2w = dict()\n",
    "\n",
    "special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "for st in special_tokens:\n",
    "    i2w[len(w2i)] = st\n",
    "    w2i[st] = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30e8c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c245bf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0, '<unk>': 1, '<sos>': 2, '<eos>': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aac6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fa767b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_type, hidden_size, word_dropout, embedding_dropout, latent_size,\n",
    "                sos_idx, eos_idx, pad_idx, unk_idx, max_sequence_length, num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.unk_idx = unk_idx\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.word_dropout_rate = word_dropout\n",
    "        self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n",
    "        \n",
    "        if rnn_type == 'rnn':\n",
    "            rnn = nn.RNN\n",
    "        elif rnn_type == 'gru':\n",
    "            rnn = nn.GRU\n",
    "        # elif rnn_type == 'lstm':\n",
    "        #     rnn = nn.LSTM\n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "        self.encoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        self.decoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.hidden_factor = (2 if bidirectional else 1) * num_layers\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.hidden2logv = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.latent2hidden = nn.Linear(latent_size, hidden_size * self.hidden_factor)\n",
    "        self.outputs2vocab = nn.Linear(hidden_size * (2 if bidirectional else 1), vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_sequence, length):\n",
    "        batch_size = input_sequence.shape[0]\n",
    "        sorted_lengths, sorted_idx = torch.sort(length, descending=True) # 按长度降序排列\n",
    "        input_sequence = input_sequence(sorted_idx)\n",
    "        \n",
    "        # Encoder\n",
    "        input_embedding = self.embedding(input_sequence)\n",
    "        \n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "        \n",
    "        _, hidden = self.encoder_rnn(packed_input)\n",
    "        \n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # flatten hidden state\n",
    "            hidden = hidden.view(batch_size, self.hidden_size*self.hidden_factor)\n",
    "        else:\n",
    "            hidden = hidden.squeeze()\n",
    "            \n",
    "        # Reparameterization\n",
    "        mean = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        \n",
    "        z = torch.randn([batch_size, self.latent_size]).to(self.device)\n",
    "        z = z * std + mean\n",
    "        \n",
    "        # Decoder \n",
    "        hidden = self.latent2hidden(z)\n",
    "\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        ## decoder input\n",
    "        if self.word_dropout_rate > 0:\n",
    "            # randomly replace decoder input with <unk>\n",
    "            prob = torch.rand(input_sequence.shape).to(self.device)\n",
    "            prob[(input_sequence.data - self.sos_idx) * (input_sequence.data - self.pad_idx) == 0] = 1\n",
    "            decoder_input_sequence = input_sequence.clone()\n",
    "            decoder_input_sequence[prob < self.word_dropout_rate] = self.unk_idx\n",
    "            input_embedding = self.embedding(decoder_input_sequence)\n",
    "        input_embedding = self.embedding_dropout(input_embedding)\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "        \n",
    "        ## decoder forward pass\n",
    "        outputs, _ = self.decoder_rnn(packed_input, hidden)\n",
    "\n",
    "        ## process outputs\n",
    "        padded_outputs = rnn_utils.pad_packed_sequence(outputs, batch_first=True)[0]\n",
    "        padded_outputs = padded_outputs.contiguous()\n",
    "        _, reversed_idx = torch.sort(sorted_idx)\n",
    "        padded_outputs = padded_outputs[reversed_idx]\n",
    "        b, s, _ = padded_outputs.size()\n",
    "        \n",
    "        ## project outputs to vocab\n",
    "        logp = nn.functional.log_softmax(self.outputs2vocab(padded_outputs.view(-1, padded_outputs.shape[2])), dim=-1)\n",
    "        logp = logp.view(b, s, self.embedding.num_embeddings)\n",
    "        \n",
    "        return logp, mean, logv, z\n",
    "    \n",
    "    def inference(self, n=4, z=None):\n",
    "\n",
    "        if z is None:\n",
    "            batch_size = n\n",
    "            z = torch.randn([batch_size, self.latent_size]).to(self.device)\n",
    "        else:\n",
    "            batch_size = z.shape[0]\n",
    "\n",
    "        hidden = self.latent2hidden(z)\n",
    "\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_size)\n",
    "\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "\n",
    "        # required for dynamic stopping of sentence generation\n",
    "        sequence_idx = torch.arange(0, batch_size, out=self.tensor()).long()  # all idx of batch\n",
    "        # all idx of batch which are still generating\n",
    "        sequence_running = torch.arange(0, batch_size, out=self.tensor()).long()\n",
    "        sequence_mask = torch.ones(batch_size, out=self.tensor()).bool()\n",
    "        # idx of still generating sequences with respect to current loop\n",
    "        running_seqs = torch.arange(0, batch_size, out=self.tensor()).long()\n",
    "\n",
    "        generations = self.tensor(batch_size, self.max_sequence_length).fill_(self.pad_idx).long()\n",
    "\n",
    "        t = 0\n",
    "        while t < self.max_sequence_length and len(running_seqs) > 0:\n",
    "\n",
    "            if t == 0:\n",
    "                input_sequence = torch.Tensor(batch_size).fill_(self.sos_idx).long().to(self.device)\n",
    "\n",
    "            input_sequence = input_sequence.unsqueeze(1)\n",
    "\n",
    "            input_embedding = self.embedding(input_sequence)\n",
    "\n",
    "            output, hidden = self.decoder_rnn(input_embedding, hidden)\n",
    "\n",
    "            logits = self.outputs2vocab(output)\n",
    "\n",
    "            input_sequence = self._sample(logits)\n",
    "\n",
    "            # save next input\n",
    "            generations = self._save_sample(generations, input_sequence, sequence_running, t)\n",
    "\n",
    "            # update gloabl running sequence\n",
    "            sequence_mask[sequence_running] = (input_sequence != self.eos_idx)\n",
    "            sequence_running = sequence_idx.masked_select(sequence_mask)\n",
    "\n",
    "            # update local running sequences\n",
    "            running_mask = (input_sequence != self.eos_idx).data\n",
    "            running_seqs = running_seqs.masked_select(running_mask)\n",
    "\n",
    "            # prune input and hidden state according to local update\n",
    "            if len(running_seqs) > 0:\n",
    "                input_sequence = input_sequence[running_seqs]\n",
    "                hidden = hidden[:, running_seqs]\n",
    "\n",
    "                running_seqs = torch.arange(0, len(running_seqs), out=self.tensor()).long()\n",
    "\n",
    "            t += 1\n",
    "\n",
    "        return generations, z\n",
    "    \n",
    "    def _sample(self, dist, mode='greedy'):\n",
    "\n",
    "        if mode == 'greedy':\n",
    "            _, sample = torch.topk(dist, 1, dim=-1)\n",
    "        sample = sample.reshape(-1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def _save_sample(self, save_to, sample, running_seqs, t):\n",
    "        # select only still running\n",
    "        running_latest = save_to[running_seqs]\n",
    "        # update token at position t\n",
    "        running_latest[:,t] = sample.data\n",
    "        # save back\n",
    "        save_to[running_seqs] = running_latest\n",
    "\n",
    "        return save_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1effa7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ts = time.strftime('%Y-%b-%d-%H:%M:%S', time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac1c95d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-Feb-18-07:19:06'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8f5595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(300, 128, 1, batch_first=True)\n",
    "input = torch.randn(32, 15, 300)\n",
    "h0 = torch.randn(1, 32, 128)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11ba2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15, 128])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c8c5ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 4, 56, 32, 43, 2]])\n",
    "p = torch.rand(a.shape)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e44a5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6438, 0.4026, 0.4299, 0.7945, 0.3941, 0.5233]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a6b94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[(a - 1) * (a - 2) == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "991b5a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.4026, 0.4299, 0.7945, 0.3941, 1.0000]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a27b0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[True, False, True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "134fa873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0200, -0.0976, -0.3032])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dceab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(32, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "981aa789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f9295a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcd26c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20b44802",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.LongTensor([[8, 10, 9, 5, 15], [2, 4, 0, 0, 0], [2, 5, 6, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2aeee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lengths, sorted_idx = torch.sort(torch.Tensor([5, 2, 3]), descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1c8bf62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = b[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83c3b32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 10,  9,  5, 15],\n",
       "        [ 2,  4,  0,  0,  0],\n",
       "        [ 2,  5,  6,  0,  0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "534b602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3., 2.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe05d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c0b431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, id = torch.sort(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e5ecf82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 10,  9,  5, 15],\n",
       "        [ 2,  5,  6,  0,  0],\n",
       "        [ 2,  4,  0,  0,  0]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0f5fcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eba13008",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_b = b[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "159e69b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 10,  9,  8,  5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb6fee56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 10, 9, 8, 5]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lengths.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c883f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rnn_utils.pack_padded_sequence(torch.randn(32, 64), list(range(32, 0, -1)), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac8fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from model import VanillaVAE\n",
    "from utils import idx2word, interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036e719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/qqp.vocab.json', 'r') as file:\n",
    "    vocab = json.load(file)\n",
    "\n",
    "w2i, i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f7fb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaVAE(\n",
    "        vocab_size=len(w2i),\n",
    "        sos_idx=w2i['<sos>'],\n",
    "        eos_idx=w2i['<eos>'],\n",
    "        pad_idx=w2i['<pad>'],\n",
    "        unk_idx=w2i['<unk>'],\n",
    "        max_sequence_length=20,\n",
    "        embedding_size=300,\n",
    "        rnn_type='gru',\n",
    "        hidden_size=256,\n",
    "        word_dropout=0.,\n",
    "        embedding_dropout=0.5,\n",
    "        latent_size=64,\n",
    "        num_layers=1,\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76e3521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('checkpoints/E9.pytorch'))\n",
    "model.load_state_dict(torch.load('checkpoints/word_dropout_0.5/E9.pytorch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a85645e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaVAE(\n",
       "  (embedding): Embedding(11042, 300)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (hidden2mean): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (hidden2logv): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (latent2hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (outputs2vocab): Linear(in_features=256, out_features=11042, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c4941b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "with open('data/qqp.train.txt') as f:\n",
    "    train_data = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "200fb18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------SAMPLES----------\n",
      "how can i stop my dog from humping my furniture ?\n",
      "how long does it take to be <unk> ?\n",
      "what should i do to beat boredom ?\n",
      "how will the implementation of gst bill and 1000 notes help to curb black money\n",
      "can you see who viewed my profile pic on quora ?\n",
      "how does donald trump realistically win the presidency ?\n",
      "what is rice puller ?\n",
      "what should i do to improve my english ?\n",
      "what are some ways to make money online ?\n",
      "is it weird to make more mistakes in the morning of the universe ?\n",
      "what is a woman ?\n",
      "can you still see who views your vote ?\n",
      "what is the difference between <unk> and <unk> ? what are they legal in the\n",
      "which is the best day of your life ?\n",
      "how can i hack a lost phone ?\n",
      "what are some arguments for hillary clinton s plans for hillary clinton ?\n",
      "what is the difference between a barrister and a <unk> ?\n",
      "how can i get into stanford with a poor gpa ?\n",
      "what is the use of the <unk> of the united states ?\n",
      "why did the <unk> <unk> <unk> <unk> <unk> ? how did they get into\n",
      "why do not many people vote for donald trump or hillary clinton ?\n",
      "can i see who viewed my instagram ?\n",
      "what is the difference between a barrister and a web developer ?\n",
      "should people over 89 not be allowed to vote ?\n",
      "can you use quora to a question on quora ?\n",
      "what is the best decision you have ever made ?\n",
      "how much money can i learn playing poker ? what are some tips ?\n",
      "what is the best way to overcome porn addiction and masturbation ?\n",
      "how can i get a second hand <unk> of the milky way to stop\n",
      "do you think chatbots can be a developed country ?\n",
      "how can i get funding for my startup idea in india ?\n",
      "what are your reviews for jee mains ?\n",
      "what are the best mystery of the world ?\n",
      "how is the indian government s decision to ban on 500 ?\n",
      "what books should i read before you ?\n",
      "what is the most embarrassing thing you have ever done ?\n",
      "what is the solution to reduce black holes ?\n",
      "how can i get more traffic to my website ?\n",
      "what are the pros and cons of having a child s mind - fi\n",
      "are there any good things about quora ?\n",
      "what are the best books for learning java ?\n",
      "what does balaji vishwanathan think about the ban of 1000 ?\n",
      "why do many people hate the world is flat ?\n",
      "should i worry about what people think about me ?\n",
      "who are the top 10 jedi in the world ?\n",
      "what is the best phone below 15000 ?\n",
      "where can i hire a legit hacker ?\n",
      "how can i get traffic to my website ?\n",
      "why india is not boycotting chinese and western cultures ?\n",
      "what are the benefits of using android devices ?\n",
      "what is the best way to learn c programming language ?\n",
      "what is the difference between scripting languages and object oriented ?\n",
      "what is the best country ?\n",
      "how does donald trump s presidency affect international students presently in america ?\n",
      "i am planning to become a millionaire before i am planning to start a business\n",
      "what is the best way to remove our existence ?\n",
      "what is the best <unk> for downloading english ?\n",
      "what is the best <unk> of <unk> ?\n",
      "what pushes do to commit suicide ?\n",
      "why are so many people obsessed with iq ?\n",
      "can i get pregnant the day of my period ends ?\n",
      "what should i do to reduce belly fat ?\n",
      "where can you find out who needs improvement of all time ?\n",
      "how can i get more of my system in two weeks ?\n",
      "what is the best way to start medical school ?\n",
      "what are <unk> in jaipur ?\n",
      "is smoking hookah worse than those cigarettes , what is it like ?\n",
      "should i learn to be a cyber security specialist ?\n",
      "what makes a person who wants to do with a basenji ?\n",
      "why does water rotate on biodiversity ?\n",
      "why are not considered a liberal ?\n",
      "what is the best phone under 15000 rs . ?\n",
      "what is the best tv series for learning ?\n",
      "what is the difference between a barrister and a <unk> ?\n",
      "i am going to be a pilot in a relationship with a 50ae desert eagle 50ae\n",
      "what pakistani people think about the uri attack ?\n",
      "what is a computer science executive ? what are some examples of disaccharides ?\n",
      "how do i become a strong strong ?\n",
      "how will it affect the year after the year 1990 if it is ?\n",
      "my questions are fine . why does not being marked as needing improvement ?\n",
      "which one is better for the world s better place in the u .\n",
      "what can i do to improve my english because i am not ?\n",
      "why is <unk> called crooked clinton ?\n",
      "what factors influence mean ?\n",
      "how can i improve my english speaking ability ? what are some tips for\n",
      "if there is a nuclear war between two and then who would be created\n",
      "why is not apple releasing the new macbook pro instead of the macbook pro\n",
      "what is the quickbooks payroll tech support number in washington ?\n",
      "if you were guaranteed <unk> in a mirror and what would you do ?\n",
      "how do you make money online ?\n",
      "how does one become mentally strong ?\n",
      "what is the best question on quora that changed your life ?\n",
      "what are the different parts of the <unk> of the <unk> ?\n",
      "how can i get rid of belly fat ?\n",
      "can you still become a doctor ?\n",
      "what is a way to stop masturbating ?\n",
      "how can i download youtube channel in english ?\n",
      "what are the best books for learning java ?\n",
      "what does the universe expand into stanford ?\n",
      "how can i hack someone s whatsapp account remotely ?\n"
     ]
    }
   ],
   "source": [
    "samples, z = model.inference(n=100)\n",
    "print('----------SAMPLES----------')\n",
    "sampled_sentences = idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])\n",
    "sampled_sentences = [' '.join(s.split()[:-1]).strip() for s in sampled_sentences]\n",
    "print(*sampled_sentences, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebfbbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "no_s = []\n",
    "for s in sampled_sentences:\n",
    "    if s in train_data:\n",
    "        n += 1\n",
    "#         print(s)\n",
    "    else:\n",
    "        no_s.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56aea24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e3bcb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 84\n",
      "1 94\n",
      "2 78\n",
      "3 102\n",
      "4 95\n",
      "5 88\n",
      "6 98\n",
      "7 95\n",
      "8 86\n",
      "9 109\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    samples, z = model.inference(n=1000)\n",
    "    sampled_sentences = idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])\n",
    "    sampled_sentences = [' '.join(s.split()[:-1]).strip() for s in sampled_sentences]\n",
    "    \n",
    "    n = 0\n",
    "    for s in sampled_sentences:\n",
    "        if s in train_data:\n",
    "            n += 1\n",
    "    print(i, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word dropout = 0.\n",
    "0 418\n",
    "1 413\n",
    "2 424\n",
    "3 402\n",
    "4 382\n",
    "5 416\n",
    "6 430\n",
    "7 432\n",
    "8 413\n",
    "9 415\n",
    "\n",
    "# word dropout = 0.5\n",
    "0 84\n",
    "1 94\n",
    "2 78\n",
    "3 102\n",
    "4 95\n",
    "5 88\n",
    "6 98\n",
    "7 95\n",
    "8 86\n",
    "9 109"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
