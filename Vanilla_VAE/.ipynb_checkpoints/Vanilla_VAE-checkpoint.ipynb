{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbae47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da09d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/clean_paraphrases.tsv'\n",
    "q1_data = []\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        q1_data.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386c3ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65eeb7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astrology : i am a capricorn sun cap moon and cap rising ... what does that say about me ?',\n",
       " 'how can i be a good geologist ?',\n",
       " 'how do i read and find my youtube comments ?',\n",
       " 'what can make physics easy to learn ?',\n",
       " 'what was your first sexual experience like ?',\n",
       " 'what would a trump presidency mean for current international master ’ s students on an f1 visa ?',\n",
       " 'what does manipulation mean ?',\n",
       " 'why are so many quora users posting questions that are readily answered on google ?',\n",
       " 'why do rockets look white ?',\n",
       " 'how should i prepare for ca final law ?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3545a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/qqp.train.txt', 'w') as f:\n",
    "    for line in q1_data[:-4000]:\n",
    "        f.write(line + '\\n') \n",
    "        \n",
    "with open('data/qqp.valid.txt', 'w') as f:\n",
    "    for line in q1_data[-4000:]:\n",
    "        f.write(line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8cb504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QQP(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, split, create_data, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split\n",
    "        self.max_sequence_length = kwargs.get('max_sequence_length', 20)\n",
    "        self.min_occ = kwargs.get('min_occ', 3)\n",
    "\n",
    "        self.raw_data_path = os.path.join(data_dir, 'qqp.'+ split +'.txt')\n",
    "        self.data_file = 'qqp.'+ split +'.json'\n",
    "        self.vocab_file = 'qqp.vocab.json'\n",
    "\n",
    "        if create_data:\n",
    "            print(\"Creating new %s qqp data.\"%split.upper())\n",
    "            self._create_data()\n",
    "\n",
    "        elif not os.path.exists(os.path.join(self.data_dir, self.data_file)):\n",
    "            print(\"%s preprocessed file not found at %s. Creating new.\"%(split.upper(), os.path.join(self.data_dir, self.data_file)))\n",
    "            self._create_data()\n",
    "\n",
    "        else:\n",
    "            self._load_data()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = str(idx)\n",
    "\n",
    "        return {\n",
    "            'input': np.asarray(self.data[idx]['input']),\n",
    "            'target': np.asarray(self.data[idx]['target']),\n",
    "            'length': self.data[idx]['length']\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.w2i)\n",
    "\n",
    "    @property\n",
    "    def pad_idx(self):\n",
    "        return self.w2i['<pad>']\n",
    "\n",
    "    @property\n",
    "    def sos_idx(self):\n",
    "        return self.w2i['<sos>']\n",
    "\n",
    "    @property\n",
    "    def eos_idx(self):\n",
    "        return self.w2i['<eos>']\n",
    "\n",
    "    @property\n",
    "    def unk_idx(self):\n",
    "        return self.w2i['<unk>']\n",
    "\n",
    "    def get_w2i(self):\n",
    "        return self.w2i\n",
    "\n",
    "    def get_i2w(self):\n",
    "        return self.i2w\n",
    "\n",
    "\n",
    "    def _load_data(self, vocab=True):\n",
    "\n",
    "        with open(os.path.join(self.data_dir, self.data_file), 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        if vocab:\n",
    "            with open(os.path.join(self.data_dir, self.vocab_file), 'r') as file:\n",
    "                vocab = json.load(file)\n",
    "            self.w2i, self.i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    def _load_vocab(self):\n",
    "        with open(os.path.join(self.data_dir, self.vocab_file), 'r') as vocab_file:\n",
    "            vocab = json.load(vocab_file)\n",
    "\n",
    "        self.w2i, self.i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    def _create_data(self):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            self._create_vocab()\n",
    "        else:\n",
    "            self._load_vocab()\n",
    "\n",
    "        tokenizer = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "        data = defaultdict(dict)\n",
    "        with open(self.raw_data_path, 'r') as f:\n",
    "\n",
    "            for i, line in enumerate(f):\n",
    "\n",
    "                words = tokenizer.tokenize(line)\n",
    "\n",
    "                input = ['<sos>'] + words\n",
    "                input = input[:self.max_sequence_length]\n",
    "\n",
    "                target = words[:self.max_sequence_length-1]\n",
    "                target = target + ['<eos>']\n",
    "\n",
    "                assert len(input) == len(target), \"%d, %d\"%(len(input), len(target))\n",
    "                length = len(input)\n",
    "\n",
    "                input.extend(['<pad>'] * (self.max_sequence_length-length))\n",
    "                target.extend(['<pad>'] * (self.max_sequence_length-length))\n",
    "\n",
    "                input = [self.w2i.get(w, self.w2i['<unk>']) for w in input]\n",
    "                target = [self.w2i.get(w, self.w2i['<unk>']) for w in target]\n",
    "\n",
    "                id = len(data)\n",
    "                data[id]['input'] = input\n",
    "                data[id]['target'] = target\n",
    "                data[id]['length'] = length\n",
    "\n",
    "        with io.open(os.path.join(self.data_dir, self.data_file), 'wb') as data_file:\n",
    "            data = json.dumps(data, ensure_ascii=False)\n",
    "            data_file.write(data.encode('utf8', 'replace'))\n",
    "\n",
    "        self._load_data(vocab=False)\n",
    "\n",
    "    def _create_vocab(self):\n",
    "\n",
    "        assert self.split == 'train', \"Vocablurary can only be created for training file.\"\n",
    "\n",
    "        tokenizer = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "        wordcounts = collections.Counter()\n",
    "        w2i = dict()\n",
    "        i2w = dict()\n",
    "\n",
    "        special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "        for st in special_tokens:\n",
    "            i2w[len(w2i)] = st\n",
    "            w2i[st] = len(w2i)\n",
    "\n",
    "        with open(self.raw_data_path, 'r') as f:\n",
    "\n",
    "            for line in f:\n",
    "                for word in tokenizer.tokenize(line):\n",
    "                    wordcounts[word] += 1\n",
    "                \n",
    "            for w, c in dict(wordcounts.most_common()).items():\n",
    "                if c > self.min_occ and w not in special_tokens:\n",
    "                    i2w[len(w2i)] = w\n",
    "                    w2i[w] = len(w2i)\n",
    "\n",
    "        assert len(w2i) == len(i2w)\n",
    "\n",
    "        print(\"Vocablurary of %i keys created.\" %len(w2i))\n",
    "\n",
    "        vocab = dict(w2i=w2i, i2w=i2w)\n",
    "        with io.open(os.path.join(self.data_dir, self.vocab_file), 'wb') as vocab_file:\n",
    "            data = json.dumps(vocab, ensure_ascii=False)\n",
    "            vocab_file.write(data.encode('utf8', 'replace'))\n",
    "\n",
    "        self._load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "457cc5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TRAIN qqp data.\n",
      "Vocablurary of 11042 keys created.\n"
     ]
    }
   ],
   "source": [
    "train_data = QQP(\n",
    "            data_dir='data',\n",
    "            split='train',\n",
    "            create_data=True,\n",
    "            max_sequence_length=20,\n",
    "            min_occ=3\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e860629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bdd7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = dict()\n",
    "i2w = dict()\n",
    "\n",
    "special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "for st in special_tokens:\n",
    "    i2w[len(w2i)] = st\n",
    "    w2i[st] = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf469a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68be585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0, '<unk>': 1, '<sos>': 2, '<eos>': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aa8f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbd18613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_type, hidden_size, word_dropout, embedding_dropout, latent_size,\n",
    "                sos_idx, eos_idx, pad_idx, unk_idx, max_sequence_length, num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.unk_idx = unk_idx\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.word_dropout_rate = word_dropout\n",
    "        self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n",
    "        \n",
    "        if rnn_type == 'rnn':\n",
    "            rnn = nn.RNN\n",
    "        elif rnn_type == 'gru':\n",
    "            rnn = nn.GRU\n",
    "        # elif rnn_type == 'lstm':\n",
    "        #     rnn = nn.LSTM\n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "        self.encoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        self.decoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.hidden_factor = (2 if bidirectional else 1) * num_layers\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.hidden2logv = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.latent2hidden = nn.Linear(latent_size, hidden_size * self.hidden_factor)\n",
    "        self.outputs2vocab = nn.Linear(hidden_size * (2 if bidirectional else 1), vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_sequence, length):\n",
    "        batch_size = input_sequence.shape[0]\n",
    "        sorted_lengths, sorted_idx = torch.sort(length, descending=True) # 按长度降序排列\n",
    "        input_sequence = input_sequence(sorted_idx)\n",
    "        \n",
    "        # Encoder\n",
    "        input_embedding = self.embedding(input_sequence)\n",
    "        \n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "        \n",
    "        _, hidden = self.encoder_rnn(packed_input)\n",
    "        \n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # flatten hidden state\n",
    "            hidden = hidden.view(batch_size, self.hidden_size*self.hidden_factor)\n",
    "        else:\n",
    "            hidden = hidden.squeeze()\n",
    "            \n",
    "        # Reparameterization\n",
    "        mean = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        \n",
    "        z = torch.randn([batch_size, self.latent_size]).to(self.device)\n",
    "        z = z * std + mean\n",
    "        \n",
    "        # Decoder \n",
    "        hidden = self.latent2hidden(z)\n",
    "\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        ## decoder input\n",
    "        if self.word_dropout_rate > 0:\n",
    "            # randomly replace decoder input with <unk>\n",
    "            prob = torch.rand(input_sequence.shape).to(self.device)\n",
    "            prob[(input_sequence.data - self.sos_idx) * (input_sequence.data - self.pad_idx) == 0] = 1\n",
    "            decoder_input_sequence = input_sequence.clone()\n",
    "            decoder_input_sequence[prob < self.word_dropout_rate] = self.unk_idx\n",
    "            input_embedding = self.embedding(decoder_input_sequence)\n",
    "        input_embedding = self.embedding_dropout(input_embedding)\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "        \n",
    "        ## decoder forward pass\n",
    "        outputs, _ = self.decoder_rnn(packed_input, hidden)\n",
    "\n",
    "        ## process outputs\n",
    "        padded_outputs = rnn_utils.pad_packed_sequence(outputs, batch_first=True)[0]\n",
    "        padded_outputs = padded_outputs.contiguous()\n",
    "        _, reversed_idx = torch.sort(sorted_idx)\n",
    "        padded_outputs = padded_outputs[reversed_idx]\n",
    "        b, s, _ = padded_outputs.size()\n",
    "        \n",
    "        ## project outputs to vocab\n",
    "        logp = nn.functional.log_softmax(self.outputs2vocab(padded_outputs.view(-1, padded_outputs.shape[2])), dim=-1)\n",
    "        logp = logp.view(b, s, self.embedding.num_embeddings)\n",
    "        \n",
    "        return logp, mean, logv, z\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a159c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(300, 128, 1, batch_first=True)\n",
    "input = torch.randn(32, 15, 300)\n",
    "h0 = torch.randn(1, 32, 128)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3192c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15, 128])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77add2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 4, 56, 32, 43, 2]])\n",
    "p = torch.rand(a.shape)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5fb35d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6438, 0.4026, 0.4299, 0.7945, 0.3941, 0.5233]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93b606cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[(a - 1) * (a - 2) == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "425c1b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.4026, 0.4299, 0.7945, 0.3941, 1.0000]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "484aaf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[True, False, True] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8280b688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0200, -0.0976, -0.3032])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f8fb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(32, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c31ad593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a77f1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d47c7184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17e6b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'batch_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6143/3866825290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpadded_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/data_ti4_d/anaconda3/envs/dingp_torch1.9.0_py37/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'batch_sizes'"
     ]
    }
   ],
   "source": [
    "padded_outputs = rnn_utils.pad_packed_sequence(outputs, batch_first=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4841a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.LongTensor([[8, 10, 9, 5, 15], [2, 4, 0, 0, 0], [2, 5, 6, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "845be3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lengths, sorted_idx = torch.sort(torch.Tensor([5, 2, 3]), descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "31708b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3., 2.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e92c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7061117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, id = torch.sort(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "065c0b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 10,  9,  5, 15],\n",
       "        [ 2,  5,  6,  0,  0],\n",
       "        [ 2,  4,  0,  0,  0]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cc66e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9197e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_b = b[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e15f45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 10,  9,  8,  5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "634417b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 10, 9, 8, 5]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lengths.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "988a7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rnn_utils.pack_padded_sequence(torch.randn(32, 64), list(range(32, 0, -1)), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da4485ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([ 2.3198e-01,  2.5610e-01, -1.0233e-01, -2.2863e-01,  2.4880e-01,\n",
       "         3.8480e-01,  1.0268e+00,  1.9357e-02,  1.4502e+00,  1.1072e+00,\n",
       "        -1.6335e+00, -3.6078e-01, -2.2025e+00,  3.0946e-01, -7.7019e-01,\n",
       "        -8.3409e-01, -8.7534e-01,  9.0640e-01,  5.1791e-01,  1.5382e+00,\n",
       "         2.0041e+00,  7.1600e-01,  3.0528e-01, -1.7164e+00, -5.3990e-01,\n",
       "         7.3630e-01, -1.4546e+00, -2.2681e-01, -1.4949e-01, -7.1822e-01,\n",
       "        -2.9656e-01, -1.5430e+00, -8.4069e-01,  5.8350e-01, -5.9392e-02,\n",
       "         9.1901e-01,  1.4210e+00,  2.6298e-01, -1.4229e-01,  3.5958e-01,\n",
       "         2.9929e-01, -1.5335e+00,  7.2855e-01,  3.2172e-01, -3.6195e-01,\n",
       "         1.1350e+00,  9.9018e-01,  1.2208e+00,  8.7524e-01,  9.8079e-01,\n",
       "        -3.6620e-01,  1.2725e+00,  3.5991e-01,  5.9394e-01, -6.1896e-01,\n",
       "        -3.8697e-01, -9.2111e-01,  5.2107e-01, -2.1829e-01,  1.6189e-01,\n",
       "         6.5652e-01, -4.9673e-02, -1.9637e+00, -5.2909e-01,  4.2492e-01,\n",
       "         7.4619e-01, -7.1681e-01, -1.7226e+00, -1.6529e+00, -3.3580e-01,\n",
       "         4.1697e-01, -1.9122e+00, -6.6097e-02, -6.1990e-01,  1.2367e+00,\n",
       "         8.8328e-01, -7.2039e-01, -6.1939e-02, -2.7850e+00, -9.5278e-01,\n",
       "        -3.2938e-01,  1.2225e+00,  6.6700e-01, -6.1201e-01,  1.2816e+00,\n",
       "        -2.5896e-01,  1.6599e+00,  8.3067e-01,  1.2771e+00, -1.4003e+00,\n",
       "        -1.4725e-01, -4.4949e-01,  1.8195e+00, -5.2032e-01,  6.6163e-01,\n",
       "        -1.2329e-01, -9.3540e-01, -9.0149e-01,  1.2113e+00, -4.2704e-01,\n",
       "        -6.4480e-01, -2.3959e+00,  2.1119e+00, -3.4082e-01,  4.0930e-01,\n",
       "        -1.4082e-01, -2.2516e+00, -6.9354e-01,  5.2047e-02, -1.4497e-01,\n",
       "        -5.1071e-01, -1.7046e+00,  8.1312e-01,  3.3747e-01,  8.0082e-01,\n",
       "         5.9402e-01,  9.7454e-01,  1.0089e+00, -3.9508e-02, -8.5745e-01,\n",
       "        -2.8299e-01, -4.5738e-01,  2.7393e-02, -8.8300e-01,  1.8016e-01,\n",
       "        -3.4742e-01, -3.7355e-01, -7.7907e-01,  1.1851e+00, -3.0573e-01,\n",
       "        -1.0117e+00, -3.6906e-02, -6.5922e-01, -1.6155e+00, -2.9204e-01,\n",
       "         4.8633e-01,  4.6797e-01,  3.5125e-01,  1.0185e+00,  5.6589e-01,\n",
       "         7.0865e-01,  2.8902e-01,  1.7223e+00,  4.1767e-01, -7.1146e-01,\n",
       "         2.9792e-02,  3.0087e-01,  5.1989e-02, -1.5620e+00, -5.9562e-01,\n",
       "        -5.7968e-01, -2.1501e-01, -4.2900e-01, -2.9093e-01,  9.8291e-01,\n",
       "         8.3839e-01, -1.5981e+00, -1.0194e+00,  1.1108e+00,  1.5988e+00,\n",
       "        -2.6372e-01,  2.7463e+00,  6.8742e-01, -7.9457e-01,  1.4278e+00,\n",
       "        -2.4944e+00,  1.0711e-01, -9.1622e-01, -1.4797e+00, -2.4498e-01,\n",
       "         3.9517e-01, -2.9470e-01, -1.8376e-01, -8.9842e-01, -1.1432e+00,\n",
       "         5.8926e-02,  8.0648e-01, -2.5029e+00,  1.7993e-02, -2.4056e-01,\n",
       "         5.8450e-01, -1.4774e+00,  2.0442e-01, -4.0726e-01, -9.3956e-01,\n",
       "        -8.8867e-02, -2.6181e-01, -1.4153e-03,  1.0016e+00, -7.7820e-01,\n",
       "        -5.4374e-01,  3.8852e-01,  2.1712e+00, -1.7143e+00, -9.0025e-03,\n",
       "         1.4832e-01,  6.3756e-01, -1.1036e+00, -5.5483e-01,  2.3303e+00,\n",
       "        -1.5424e+00,  8.5859e-01, -9.7679e-01,  5.8853e-01, -1.0581e+00,\n",
       "         3.6716e-02,  7.6440e-01, -4.7358e-01,  1.0743e-01,  1.9983e+00,\n",
       "        -8.2161e-02, -7.6143e-01,  1.4272e+00,  2.6507e-01, -4.3904e-03,\n",
       "        -6.0191e-01, -3.6162e-01, -4.7552e-01,  8.6830e-03,  2.6841e-02,\n",
       "         2.2006e-02, -6.2862e-01,  9.0004e-01,  2.9527e-01, -1.6873e-01,\n",
       "        -1.5372e+00,  6.0340e-01,  6.0821e-01, -2.5854e-01, -4.1941e-01,\n",
       "         2.1860e-02, -7.7521e-02,  4.1784e-01,  2.3090e+00,  3.0701e-01,\n",
       "         3.6575e-01,  3.9549e-01, -9.7319e-01, -6.7430e-01, -8.7587e-01,\n",
       "        -6.1012e-01,  2.2831e-01, -1.2624e+00,  7.7798e-01,  1.5927e+00,\n",
       "         6.1749e-01,  3.6530e-01, -1.0700e+00, -7.9292e-01, -3.9158e-01,\n",
       "        -7.7485e-02, -5.6622e-01, -7.6139e-01, -1.2763e+00,  2.3916e+00,\n",
       "         5.3624e-01,  1.2872e+00, -1.4709e+00,  8.5067e-01, -2.0818e+00,\n",
       "         1.2884e+00, -1.4040e+00, -1.4075e-01,  8.6958e-01, -7.4936e-02,\n",
       "        -3.3975e-03,  3.0994e-01, -1.1163e+00,  2.0834e+00,  6.4862e-01,\n",
       "        -1.4356e-01,  6.1093e-01,  9.7078e-01, -1.2187e+00, -7.0206e-01,\n",
       "        -3.1012e-01,  1.1952e+00, -1.6043e+00, -2.3997e-01, -7.7985e-01,\n",
       "         2.1049e-01, -3.9005e-01,  7.9243e-01, -5.6317e-01, -1.1652e+00,\n",
       "         1.1911e+00,  2.0950e-01, -4.6880e-01, -4.6766e-01,  2.6608e-01,\n",
       "        -9.0998e-01, -2.4052e+00,  1.2492e+00, -1.5406e-01, -7.0904e-01,\n",
       "         1.2067e+00,  3.7390e-01, -6.1628e-02, -6.4672e-01, -1.8924e-01,\n",
       "        -1.0578e+00,  1.8720e+00, -5.2626e-01, -2.2545e-01, -4.6560e-01,\n",
       "        -1.8745e+00, -1.1904e-01, -1.6200e+00, -1.7666e-01,  1.2844e-01,\n",
       "        -1.4702e+00, -1.5354e+00, -1.4287e+00,  6.9713e-01,  7.1998e-01,\n",
       "         2.9476e-01,  1.1506e+00, -6.3329e-01,  1.8459e+00,  5.5609e-01,\n",
       "         1.3139e-01, -5.1935e-01,  1.2382e+00, -1.6731e-01, -1.5115e-01,\n",
       "        -1.7257e+00, -9.3522e-01,  1.0810e+00, -2.5112e+00,  1.1970e+00,\n",
       "        -2.1011e-01,  8.8757e-01, -1.0990e+00,  1.4997e-01, -6.4029e-01,\n",
       "        -9.7263e-02, -1.0514e+00, -1.4529e+00, -3.7628e-01,  2.3408e-01,\n",
       "        -3.4068e-01, -5.8684e-01,  9.3911e-01,  1.3564e-01, -1.4756e+00,\n",
       "        -2.9683e-01,  4.2429e-01, -2.3837e-01,  1.8721e+00,  1.5427e-02,\n",
       "         8.6956e-01,  9.5946e-01, -1.8547e+00,  1.2130e+00,  1.7711e+00,\n",
       "        -3.7053e-01,  6.6409e-01,  4.4067e-01,  8.4335e-01,  8.9216e-01,\n",
       "        -8.7186e-01, -1.5604e+00,  6.8953e-03,  4.9540e-01,  8.2252e-01,\n",
       "        -7.9571e-01,  1.0110e+00, -7.5086e-01,  2.1905e+00,  8.0652e-01,\n",
       "         1.2624e-01,  1.0155e+00, -2.3771e-02,  2.6876e-01, -1.3057e-01,\n",
       "        -1.7160e+00,  2.8110e-01, -7.3118e-01,  2.2108e-01,  8.5784e-01,\n",
       "         1.2893e-01,  6.4558e-01, -1.8187e-01,  8.1712e-01, -1.1426e+00,\n",
       "        -2.6259e-01, -5.9275e-01, -3.8133e-01,  2.2245e+00,  2.0090e-01,\n",
       "        -6.1332e-01, -1.0773e-01, -3.8624e-01, -2.4704e+00,  1.9859e-01,\n",
       "         6.7832e-01, -7.9149e-01,  2.3393e-01,  1.0224e+00,  7.9435e-02,\n",
       "         2.5205e+00, -2.4877e+00, -9.7246e-01, -6.0677e-01, -3.5270e-01,\n",
       "        -1.1803e-01,  5.3950e-01,  3.4838e-02, -3.1168e-01, -4.5502e-01,\n",
       "        -1.0388e+00,  5.2463e-01,  1.4683e+00,  1.5930e+00, -6.0922e-01,\n",
       "         6.8843e-01, -1.0984e+00, -2.3873e-01,  4.6097e-01, -6.6876e-01,\n",
       "        -5.4191e-01,  2.3131e-01,  1.5060e+00, -1.1104e+00,  4.7848e-01,\n",
       "         1.1017e+00,  9.1270e-01, -1.1523e+00, -5.5853e-01,  4.8087e-01,\n",
       "        -7.1871e-01, -8.0073e-01, -9.5032e-01, -4.5273e-01,  5.1092e-02,\n",
       "         1.1104e+00,  6.7684e-01, -1.6283e+00, -4.8353e-02,  6.6834e-01,\n",
       "        -1.5118e+00, -1.0583e+00, -2.3211e-01, -2.4551e-01,  5.9757e-01,\n",
       "         5.9980e-01, -8.4923e-01, -8.6989e-01,  9.6547e-01, -7.5733e-01,\n",
       "        -1.9545e-01, -5.2986e-01,  7.2878e-01,  2.1969e+00,  1.1555e+00,\n",
       "         1.7643e-01,  1.2070e+00, -7.0024e-01, -6.0281e-01,  1.4838e+00,\n",
       "        -3.5962e-01,  3.5326e-01, -3.2264e-01, -1.6234e-01,  3.4029e-01,\n",
       "        -3.7651e-01,  5.2007e-01, -6.2760e-01, -8.5580e-02, -2.5887e-01,\n",
       "        -6.2748e-01, -1.5577e+00, -8.2474e-01,  7.3440e-04,  8.5132e-01,\n",
       "         5.4992e-01, -2.5659e-01, -4.9488e-01, -1.6847e+00, -2.0393e-01,\n",
       "        -4.3388e-01, -2.8516e+00,  6.9828e-01, -6.9854e-01, -7.8117e-01,\n",
       "        -4.8247e-01, -9.8710e-01, -2.5795e-01,  1.3601e+00, -6.7718e-01,\n",
       "        -1.9089e+00,  1.7871e-01, -1.0202e+00,  1.4121e+00,  4.2579e-01,\n",
       "         7.3009e-02, -8.7578e-01, -9.0579e-01,  1.1042e+00,  9.9299e-02,\n",
       "        -1.0874e+00,  9.0285e-01,  4.4187e-01,  3.7091e-01, -3.2607e-01,\n",
       "         6.2715e-01, -2.2223e-01,  3.0169e-01,  2.2118e+00, -1.8629e+00,\n",
       "         1.6322e+00,  3.5488e-01, -1.9411e+00,  1.2868e-01,  6.3123e-01,\n",
       "         1.1122e+00, -1.5259e-01,  3.2748e-02,  7.2371e-01,  4.6128e-02,\n",
       "        -4.5267e-01, -5.9242e-02, -4.3320e-01,  1.0308e+00, -3.5849e-02,\n",
       "        -1.8943e+00,  1.5507e+00, -9.9174e-01]), batch_sizes=tensor([32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "        14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927ee28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
